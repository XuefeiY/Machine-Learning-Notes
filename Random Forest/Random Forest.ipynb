{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random  Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From bagging to random forests\n",
    "Further improvements can be made to prediction accuracy by growing decorrelated trees in each bagged sample.\n",
    "Random forests still use bootstrap samples, but only use m out of p predictors at each split (typically, for classification problem, $m \\approx \\sqrt(p)$; for regression problem,  $m \\approx \\frac{p}{3}$.)\n",
    "Still get the useful variable importance measures and out-of-bag error estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "No formal distributional assumptions, random forests are non-parametric and can thus handle skewed and multi-modal data as well as categorical data that are ordinal or non-ordinal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pros and Cons\n",
    "### Pros\n",
    "* RF is good for parallel or distributed computing.\n",
    "* Almost always have lower classification error and better f-scores than decision trees.\n",
    "* Almost always perform as well as or better than SVMs, but are far easier for humans to understand.\n",
    "* Deal really well with uneven data sets that have missing variables.\n",
    "* Give you a really good idea of which features in your data set are the most important for free.\n",
    "* Decorrelates trees (relative to bagged trees)\n",
    "  * important when dealing with mulitple features which may be correlated\n",
    "* reduced variance (relative to regular trees)\n",
    "\n",
    "### Cons\n",
    "* Not as easy to visually interpret\n",
    "* time-consuming, slow in generating predictions because it has multiple de\n",
    "* Can overfit datasets that are particularly noisy\n",
    "* For data including categorical predictor variables with different number of levels, random forests are biased in favor of those predictors with more levels. Therefore, the variable importance scores from random forest are not always reliable for this type of data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
